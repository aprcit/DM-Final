import torch
import torch.nn.functional as F
import numpy as np
from torch_geometric.data import Data
from torch_geometric.nn import GATConv
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt
import pandas as pd

#-------------------------------------------1.加载数据并预处理--------------------------
def load_data_2(dataset='citeseer'):
    path = r'data_2\{}'.format(dataset)

    text = []
    with open(path+'.text', 'r', encoding='utf-8') as f:
        for line in f.readlines():
            text.append(line.strip().split(maxsplit=1)[1])
    
    vectorizer = CountVectorizer()
    feature_arr = vectorizer.fit_transform(text).toarray()

    label = []
    with open(path+'.label', 'r', encoding='utf-8') as f:
        for line in f.readlines():
            label.append(int(line.strip().split()[1]))  # 直接提取标签值
    label_arr = np.array(label)

    adj = np.zeros((label_arr.shape[0], label_arr.shape[0]), dtype=np.int8)
    with open(path+'.edge', 'r', encoding='utf-8') as f:
        for line in f.readlines():
            nodes = [int(k) for k in line.strip().split()]
            adj[nodes[0], nodes[1]] = 1

    return feature_arr, label_arr, adj
#--------------------------------------------2.定义模型-----------------------------
# 设置随机种子以确保可重复性
seed = 52
torch.manual_seed(seed)
np.random.seed(seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(seed)

# 定义GAT模型
class GAT(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.6):
        super(GAT, self).__init__()
        # 第一层GAT卷积层，使用多头注意力机制
        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)
        # 第二层GAT卷积层，使用单头注意力机制并输出最终分类结果
        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False,
                             dropout=dropout)
        # 存储dropout参数
        self.dropout = dropout

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        # 对输入特征进行dropout处理
        x = F.dropout(x, p=self.dropout, training=self.training)
        # 第一层卷积操作后应用ELU激活函数
        x = F.elu(self.conv1(x, edge_index))
        # 再次对特征进行dropout处理
        x = F.dropout(x, p=self.dropout, training=self.training)
        # 第二层卷积操作
        x = self.conv2(x, edge_index)
        # 应用log softmax得到最终的概率分布
        return F.log_softmax(x, dim=1)
def preprocess_data(features, labels, adjacency_matrix):
    num_nodes = features.shape[0]
    # 将邻接矩阵转换为边索引
    edge_index = torch.tensor(np.stack(np.where(adjacency_matrix != 0)), dtype=torch.long)
    # 将特征矩阵转换为PyTorch张量
    x = torch.tensor(features, dtype=torch.float)
    # 将标签数组转换为PyTorch张量
    y = torch.tensor(labels, dtype=torch.long)

    # 创建训练、验证和测试掩码
    idx = list(range(num_nodes))
    idx_train, idx_test = train_test_split(idx, test_size=0.2, random_state=seed)
    idx_train, idx_val = train_test_split(idx_train, test_size=0.25, random_state=seed)

    train_mask = torch.zeros(num_nodes, dtype=torch.bool)
    val_mask = torch.zeros(num_nodes, dtype=torch.bool)
    test_mask = torch.zeros(num_nodes, dtype=torch.bool)
    train_mask[idx_train] = True
    val_mask[idx_val] = True
    test_mask[idx_test] = True

    # 创建Data对象
    data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)
    return data
#-------------------------------------------------3.训练模型-------------------------
def train(model, data, optimizer, criterion):
    model.train()
    optimizer.zero_grad()
    output = model(data)
    # 计算损失
    loss = criterion(output[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

@torch.no_grad()
def evaluate(model, data, criterion, mask):
    model.eval()
    logits = model(data)
    # 计算损失
    loss = criterion(logits[mask], data.y[mask]).item()
    pred = logits.argmax(dim=1)
    correct = int(pred[mask].eq(data.y[mask]).sum().item())
    acc = correct / int(mask.sum())
    return loss, acc

if __name__ == "__main__":
    features, labels, adjacency_matrix = load_data_2()
    data = preprocess_data(features, labels, adjacency_matrix)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    data = data.to(device)

    # 初始化GAT模型（确定超参数值）
    model = GAT(in_channels=data.num_node_features, hidden_channels=32, out_channels=6, heads=8, dropout=0.5).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=5e-4)  # 增加L2正则化
    criterion = torch.nn.NLLLoss()

    best_val_acc = 0
    patience = 100
    epochs_without_improvement = 0

    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []
    test_losses = []
    test_accuracies = []

    for epoch in range(1, 201):
        loss = train(model, data, optimizer, criterion)
        train_loss, train_acc = evaluate(model, data, criterion, data.train_mask)
        val_loss, val_acc = evaluate(model, data, criterion, data.val_mask)
        test_loss, test_acc = evaluate(model, data, criterion, data.test_mask)
        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f},Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')

        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)
        test_losses.append(test_loss)
        test_accuracies.append(test_acc)

        # 更新最佳验证准确率和早停计数器（防止过拟合）
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            epochs_without_improvement = 0
        else:
            epochs_without_improvement += 1
        
        # 如果超过耐心值，提前停止训练
        if epochs_without_improvement >= patience:
            print("Early stopping")
            break

    # ----------------------------------------4.评估模型------------------------------------------
    test_loss, test_acc = evaluate(model, data, criterion, data.test_mask)
    print(f'Test Accuracy: {test_acc:.4f}')

    # 模型性能表
    performance_metrics = {
        'Metric': ['Train Loss', 'Train Accuracy', 'Validation Loss', 'Validation Accuracy', 'Test Accuracy'],
        'Value': [train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1], test_acc]
    }
    df_performance = pd.DataFrame(performance_metrics)

    print("\nModel Performance Metrics:")
    print(df_performance)

    # ----------------------------------------5.可视化训练过程---------------------------------------------
plt.figure(figsize=(12, 6))
# 绘制损失图
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.plot(test_losses, label='Test Loss') 
plt.title('Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# 绘制准确率图
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Train Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')  
plt.title('Accuracy over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()    

plt.tight_layout()
plt.show()
